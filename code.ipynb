{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b47f33b-07a8-4777-a1b2-9e691dd93a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marko/Desktop/JBrains/Code_completion/code_completion/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from typing import List\n",
    "\n",
    "checkpoint = \"bigcode/tiny_starcoder_py\"\n",
    "device = \"cpu\" # \"cuda\" for GPU usage or \"cpu\" for CPU usage\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00628db9-e548-43f5-85d2-fc3b3bbcf725",
   "metadata": {},
   "source": [
    "File that would provide testing examples only contains functions (plus some imported modules). The idea is to split it by the keyword def. The prefix is the function header, the suffix is the return statement (if it exists) and the middle part is the body of the function. In certain cases 2 examples are created (the other example includes imported modules in the prefix in order to help the model with generating correct code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84ee96cc-01ff-45df-96fa-e5bcc19704cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'examples/test.py'\n",
    "text_list = []\n",
    "with open(path) as file:\n",
    "    text_list = file.read().split('def')\n",
    "\n",
    "input_text_list = []\n",
    "y_true = []\n",
    "for i in range(1, len(text_list)):\n",
    "    input_text = text_list[i]\n",
    "    input_text_lines = input_text.split('\\n')\n",
    "\n",
    "    input_text_prefix = '<fim_prefix>def'+input_text_lines[0]\n",
    "        \n",
    "    input_text_lines[-3] = '<fim_suffix>'+input_text_lines[-3]+'<fim_middle>'\n",
    "    input_text_list.append(input_text_prefix+input_text_lines[-3])\n",
    "\n",
    "    solution = ''\n",
    "    for i in range(1, len(input_text_lines)-3):\n",
    "        solution += input_text_lines[i]+'\\n'\n",
    "    y_true.append(solution)\n",
    "\n",
    "    #help model with calculating distances by suggesting to use numpy module\n",
    "    if i == 1 or i == 2:\n",
    "        input_text_prefix = '<fim_prefix>'+'import numpy as np\\n\\n'+'def'+input_text_lines[0]\n",
    "        input_text_list.append(input_text_prefix+input_text_lines[-3])\n",
    "\n",
    "        solution = ''\n",
    "        for i in range(1, len(input_text_lines)-3):\n",
    "            solution += input_text_lines[i]+'\\n'\n",
    "        y_true.append(solution)\n",
    "\n",
    "    #help model with reading fasta files by suggesting to use SeqIO module from Bio \n",
    "    if i == 3:\n",
    "        input_text_prefix = '<fim_prefix>'+'from Bio import SeqIO\\n\\n'+'def'+input_text_lines[0]\n",
    "        input_text_list.append(input_text_prefix+input_text_lines[-3])\n",
    "\n",
    "        solution = ''\n",
    "        for i in range(1, len(input_text_lines)-3):\n",
    "            solution += input_text_lines[i]+'\\n'\n",
    "        y_true.append(solution)\n",
    "\n",
    "#return text_list to default state\n",
    "text_list[1 :] = ['def'+text_list[i] for i in range(1, len(text_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a4b2fa9-ec89-405c-a1c3-b2583b04cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_middle_formatting(y_true: List[str], first_pattern: str, last_pattern: str, text: str) -> str:\n",
    "    first_pattern_id = text.find(first_pattern)\n",
    "    last_pattern_id = first_pattern_id + 1 + text[first_pattern_id+1 :].find(last_pattern)\n",
    "\n",
    "    # value that should be predicted\n",
    "    y_true.append(text[first_pattern_id : last_pattern_id])\n",
    "    \n",
    "    return '<fim_prefix>'+text[: first_pattern_id]+'<fim_suffix>'+text[last_pattern_id :]+'<fim_middle>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defc1026-6561-4ef6-bb9a-184045822594",
   "metadata": {},
   "source": [
    "Function five_adic_codon_encoding and five_adic_codon_distance appear to be less generally known than others. So the idea is to help the model by providing it some parts of the code from the body of the function. Since the five_adic_distance requires five_adic_encoding, the third example will contain the whole five_adic_encoding function in its prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5fe1aaa-a7f3-474f-8159-20a87ccdfbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#five_adic_codon_encoding\n",
    "input_text_list.append(drop_middle_formatting(y_true, 'elif', 'elif', text_list[4]))\n",
    "#five_adic_codon_distance\n",
    "input_text_list.append(drop_middle_formatting(y_true, 'elif', 'elif', text_list[5]))\n",
    "#previous 2 functions together\n",
    "input_text_list.append(drop_middle_formatting(y_true, 'elif int', 'elif encoded', text_list[4]+text_list[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8b3708-3b41-4d7e-a552-235c2fbc01ab",
   "metadata": {},
   "source": [
    "Manhattan distance and Euclidean distance with parts of the function body provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f03728-f5b3-4dcf-b0a2-88d2db13f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manhattan distance\n",
    "input_text_list.append(drop_middle_formatting(y_true, 'diff', 'distance', text_list[1]))\n",
    "input_text_list.append(drop_middle_formatting(y_true, 'distance =', 'return', text_list[1]))\n",
    "#Euclidean distance\n",
    "input_text_list.append(drop_middle_formatting(y_true, 'diff', 'distance', text_list[2]))\n",
    "input_text_list.append(drop_middle_formatting(y_true, 'distance =', 'return', text_list[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c96649-dba7-46f6-9fc0-805e8c6918ab",
   "metadata": {},
   "source": [
    "Providing functions that aren't connected to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c465665-f66f-4c3f-b03c-d7ce91a95dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_list.append(drop_middle_formatting(y_true, 'def print_hello', '\\n', text_list[7]+text_list[8]))\n",
    "input_text_list.append(drop_middle_formatting(y_true, 'print(', 'print(', text_list[5]+text_list[7]))\n",
    "input_text_list.append(drop_middle_formatting(y_true, 'open(', '\\n', text_list[1]+text_list[2]+text_list[3]))\n",
    "\n",
    "len(input_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6224bacd-460b-4b9c-8933-5dca71e85f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_text = \"<fim_prefix>def print_one_two_three():\\n    print('one')\\n    <fim_suffix>   print('three')\\n   <fim_middle>\"\n",
    "#input_text = \"<fim_prefix>def print_hello_world():\\n  <fim_suffix>\\n <fim_middle>\"\n",
    "#input_text = \"<fim_prefix>from Bio import SeqIO\\nwith open(filePath) as file:\\n  <fim_suffix>return fasta_sequences_sars1\\n <fim_middle>\"\n",
    "inputs_list = [tokenizer.encode(input_text, return_tensors=\"pt\").to(device) for input_text in input_text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "446941f8-d35e-4fd9-9195-6b5d1dd1e74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "outputs_list = [model.generate(inputs, max_new_tokens=100) for inputs in inputs_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a90309f8-8cc5-41ab-bd54-1d9d33c658fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">def Manhattan_distance(vector1: List[int], vector2: List[int]) -> int:\n",
      ">    return distance\n",
      "Predicted:\n",
      ">\n",
      "        distance = 0\n",
      "        for i in range(len(vector1)):\n",
      "            distance += abs(vector1[i] - vector2[i])\n",
      "    <|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">import numpy as np\n",
      "\n",
      "def Manhattan_distance(vector1: List[int], vector2: List[int]) -> int:\n",
      ">    return distance\n",
      "Predicted:\n",
      ">\n",
      "    distance = 0\n",
      "    for i in range(len(vector1)):\n",
      "        distance += abs(vector1[i] - vector2[i])\n",
      "    return distance\n",
      "\n",
      "def Manhattan_distance_matrix(vector1: List[int], vector2: List[int]) -> np.ndarray:\n",
      "    distance = np.zeros((len(vector1), len(vector2)))\n",
      "    for i in range(len(vector1)):\n",
      "        distance[i, :]\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def Euclidean_distance(vector1: List[int], vector2: List[int]) -> int:\n",
      ">    return distance\n",
      "Predicted:\n",
      ">\n",
      "        return sum(abs(v1 - v2) for v1, v2 in zip(vector1, vector2))\n",
      "\n",
      "<|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">import numpy as np\n",
      "\n",
      "def Euclidean_distance(vector1: List[int], vector2: List[int]) -> int:\n",
      ">    return distance\n",
      "Predicted:\n",
      ">\n",
      "    return np.sqrt(np.sum(np.square(vector1 - vector2)))\n",
      "\n",
      "def Euclidean_distance_matrix(vector1: List[int], vector2: List[int]) -> np.ndarray:\n",
      "    return np.array([Euclidean_distance(vector1, vector2), Euclidean_distance(vector2, vector1)])\n",
      "\n",
      "def Euclidean_distance_matrix_vector(vector1: List[int], vector2: List\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def read_data(filePath: str):\n",
      ">    return fasta_sequences_sars1\n",
      "Predicted:\n",
      ">\n",
      "    fasta_sequences_sars1 = []\n",
      "    fasta_sequences_sars2 = []\n",
      "    fasta_sequences_sars3 = []\n",
      "    fasta_sequences_sars4 = []\n",
      "    fasta_sequences_sars5 = []\n",
      "    fasta_sequences_sars6 = []\n",
      "    fasta_sequences_sars7 = []\n",
      "    fasta_sequences_sars8 = []\n",
      "    fasta_sequences_sars9 = []\n",
      "   \n",
      "-----------------------------------------------------\n",
      "\n",
      ">import numpy as np\n",
      "\n",
      "def read_data(filePath: str):\n",
      ">    return fasta_sequences_sars1\n",
      "Predicted:\n",
      ">\n",
      "    fasta_sequences_sars1 = []\n",
      "    fasta_sequences_sars2 = []\n",
      "    fasta_sequences_sars3 = []\n",
      "    fasta_sequences_sars4 = []\n",
      "    fasta_sequences_sars5 = []\n",
      "    fasta_sequences_sars6 = []\n",
      "    fasta_sequences_sars7 = []\n",
      "    fasta_sequences_sars8 = []\n",
      "    fasta_sequences_sars9 = []\n",
      "   \n",
      "-----------------------------------------------------\n",
      "\n",
      ">def five_adic_codon_encoding(rna_codon: str) -> int:\n",
      ">    return int(encoding)\n",
      "Predicted:\n",
      ">\n",
      "    encoding = 0\n",
      "    for i in rna_codon:\n",
      "        if i == 'A':\n",
      "            encoding += 1\n",
      "    <|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def five_adic_codon_distance(codon1: str, codon2: str) -> int:\n",
      ">    return distance\n",
      "Predicted:\n",
      ">\n",
      "    distance = 0\n",
      "    for i in range(len(codon1)):\n",
      "        for j in range(len(codon2)):\n",
      "            if codon1[i] == codon2[j]:\n",
      "                distance += 1\n",
      "    return distance\n",
      "\n",
      "\n",
      "def five_adic_codon_distance_2(codon1: str, codon2: str) -> int:\n",
      "    distance = 0\n",
      "    for i in range(len(codon1)):\n",
      "        for\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def print_one_two_three():\n",
      ">    print('three')\n",
      "Predicted:\n",
      ">\n",
      "    print('one')\n",
      "    print('two')\n",
      "    print('three')\n",
      "<|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">import numpy as np\n",
      "\n",
      "def print_one_two_three():\n",
      ">    print('three')\n",
      "Predicted:\n",
      ">\n",
      "    print('one')\n",
      "    print('two')\n",
      "    print('three')\n",
      "<|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def print_one_until_three():\n",
      ">    print('three')\n",
      "Predicted:\n",
      ">\n",
      "    print('one')\n",
      "<|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">import numpy as np\n",
      "\n",
      "def print_one_until_three():\n",
      ">    print('three')\n",
      "Predicted:\n",
      ">\n",
      "    print('one')\n",
      "<|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def print_hello_world():\n",
      ">\n",
      "Predicted:\n",
      ">\n",
      "    print(\"Hello World!\")\n",
      "<|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">import numpy as np\n",
      "\n",
      "def print_hello_world():\n",
      ">\n",
      "Predicted:\n",
      ">\n",
      "    print(\"Hello World!\")\n",
      "<|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def five_adic_codon_encoding(rna_codon: str) -> int:\n",
      "    #encode RNA codon (triplet) as one number in 5-adic system\n",
      "    encoding = ''\n",
      "    \n",
      "    for nucleotide in rna_codon:\n",
      "        if nucleotide == 'C':\n",
      "            encoding += '1'\n",
      "        \n",
      ">elif nucleotide == 'T':\n",
      "            encoding += '3'\n",
      "        else: # nucleotide == G\n",
      "            encoding += '4'\n",
      "            \n",
      "    return int(encoding)\n",
      "\n",
      "\n",
      "Predicted:\n",
      ">elif nucleotide == 'G':\n",
      "            encoding += '2'\n",
      "        <|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def five_adic_codon_distance(codon1: str, codon2: str) -> int:\n",
      "    encoded_codon1 = five_adic_codon_encoding(codon1)\n",
      "    encoded_codon2 = five_adic_codon_encoding(codon2)\n",
      "    \n",
      "    distance = 0\n",
      "    if int(encoded_codon1/100) != int(encoded_codon2/100):\n",
      "        distance = 1\n",
      "\n",
      "    \n",
      ">elif encoded_codon1 % 10 != encoded_codon2 % 10:\n",
      "        if abs(encoded_codon1 % 10 - encoded_codon2 % 10) == 2:\n",
      "            distance = 1/2*1/25\n",
      "        else:\n",
      "            distance = 1*1/25\n",
      "    return distance\n",
      "\n",
      "\n",
      "Predicted:\n",
      ">distance = distance + five_adic_codon_distance(encoded_codon1, encoded_codon2)\n",
      "    return distance\n",
      "\n",
      "\n",
      "def five_adic_codon_encoding(codon: str) -> str:\n",
      "    encoded_codon = str(codon)\n",
      "    encoded_codon = encoded_codon.replace(\"0\", \"\")\n",
      "    encoded_codon = encoded_codon.replace(\"1\", \"\")\n",
      "    encoded_codon = encoded_cod\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def five_adic_codon_encoding(rna_codon: str) -> int:\n",
      "    #encode RNA codon (triplet) as one number in 5-adic system\n",
      "    encoding = ''\n",
      "    \n",
      "    for nucleotide in rna_codon:\n",
      "        if nucleotide == 'C':\n",
      "            encoding += '1'\n",
      "        elif nucleotide == 'A':\n",
      "            encoding += '2'\n",
      "        elif nucleotide == 'T':\n",
      "            encoding += '3'\n",
      "        else: # nucleotide == G\n",
      "            encoding += '4'\n",
      "            \n",
      "    return int(encoding)\n",
      "\n",
      "def five_adic_codon_distance(codon1: str, codon2: str) -> int:\n",
      "    encoded_codon1 = five_adic_codon_encoding(codon1)\n",
      "    encoded_codon2 = five_adic_codon_encoding(codon2)\n",
      "    \n",
      "    distance = 0\n",
      "    if int(encoded_codon1/100) != int(encoded_codon2/100):\n",
      "        distance = 1\n",
      "\n",
      "    \n",
      ">elif encoded_codon1 % 10 != encoded_codon2 % 10:\n",
      "        if abs(encoded_codon1 % 10 - encoded_codon2 % 10) == 2:\n",
      "            distance = 1/2*1/25\n",
      "        else:\n",
      "            distance = 1*1/25\n",
      "    return distance\n",
      "\n",
      "\n",
      "Predicted:\n",
      ">distance = distance + five_adic_codon_distance(encoded_codon1, encoded_codon2)\n",
      "    \n",
      "    return distance\n",
      "\n",
      "def five_adic_codon_distance_from_codon(codon: str) -> int:\n",
      "    encoded_codon = five_adic_codon_encoding(codon)\n",
      "    \n",
      "    distance = 0\n",
      "    if encoded_codon % 10 == 0:\n",
      "        distance = 1/2*1/\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def Manhattan_distance(vector1: List[int], vector2: List[int]) -> int:\n",
      "    \n",
      ">distance = sum([abs(x) for x in diff])\n",
      "    return distance\n",
      "\n",
      "\n",
      "Predicted:\n",
      ">diff = [abs(x) for x in vector1]\n",
      "    <|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def Manhattan_distance(vector1: List[int], vector2: List[int]) -> int:\n",
      "    diff = np.array(vector1) - np.array(vector2)\n",
      "    \n",
      ">return distance\n",
      "\n",
      "\n",
      "Predicted:\n",
      ">distance = np.linalg.norm(diff)\n",
      "    <|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def Euclidean_distance(vector1: List[int], vector2: List[int]) -> int:\n",
      "    \n",
      ">distance = np.sqrt(np.sum(diff))\n",
      "    return distance\n",
      "\n",
      "\n",
      "Predicted:\n",
      ">diff = np.subtract(vector1, vector2)\n",
      "    <|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def Euclidean_distance(vector1: List[int], vector2: List[int]) -> int:\n",
      "    diff = (np.array(vector1) - np.array(vector2))**2\n",
      "    \n",
      ">return distance\n",
      "\n",
      "\n",
      "Predicted:\n",
      ">distance = np.sqrt(np.sum(diff))\n",
      "    <|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def print_one_until_three():\n",
      "    print('one')\n",
      "    print('two')\n",
      "    print('three')\n",
      "\n",
      "\n",
      ">\n",
      "    print(\"Hello world!\")\n",
      "\n",
      "\n",
      "\n",
      "Predicted:\n",
      ">def print_one_until_four():\n",
      "    print('one')\n",
      "    print('two')\n",
      "    print('three')\n",
      "\n",
      "\n",
      "def print_one_until_five():\n",
      "    print('one')\n",
      "    print('two')\n",
      "    print('three')\n",
      "\n",
      "\n",
      "def print_one_until_six():\n",
      "    print('one')\n",
      "    print('two')\n",
      "    print('three')\n",
      "\n",
      "\n",
      "def print_one_until_seven():\n",
      "    print('one')\n",
      "    print('two')\n",
      "    print\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def five_adic_codon_distance(codon1: str, codon2: str) -> int:\n",
      "    encoded_codon1 = five_adic_codon_encoding(codon1)\n",
      "    encoded_codon2 = five_adic_codon_encoding(codon2)\n",
      "    \n",
      "    distance = 0\n",
      "    if int(encoded_codon1/100) != int(encoded_codon2/100):\n",
      "        distance = 1\n",
      "\n",
      "    elif int(encoded_codon1/10) != int(encoded_codon2/10):\n",
      "        distance = 1/5\n",
      "        \n",
      "    elif encoded_codon1 % 10 != encoded_codon2 % 10:\n",
      "        if abs(encoded_codon1 % 10 - encoded_codon2 % 10) == 2:\n",
      "            distance = 1/2*1/25\n",
      "        else:\n",
      "            distance = 1*1/25\n",
      "    return distance\n",
      "\n",
      "def print_one_until_three():\n",
      "    \n",
      ">print('two')\n",
      "    print('three')\n",
      "\n",
      "\n",
      "Predicted:\n",
      ">print('one')\n",
      "    print('two')\n",
      "    print('three')\n",
      "\n",
      "def print_one_until_four():\n",
      "    <|endoftext|>\n",
      "-----------------------------------------------------\n",
      "\n",
      ">def Manhattan_distance(vector1: List[int], vector2: List[int]) -> int:\n",
      "    diff = np.array(vector1) - np.array(vector2)\n",
      "    distance = sum([abs(x) for x in diff])\n",
      "    return distance\n",
      "\n",
      "def Euclidean_distance(vector1: List[int], vector2: List[int]) -> int:\n",
      "    diff = (np.array(vector1) - np.array(vector2))**2\n",
      "    distance = np.sqrt(np.sum(diff))\n",
      "    return distance\n",
      "\n",
      "def read_data(filePath: str):\n",
      "    with \n",
      ">\n",
      "        fasta_sequences_sars1 = SeqIO.parse(file,'fasta')\n",
      "    return fasta_sequences_sars1\n",
      "\n",
      "\n",
      "Predicted:\n",
      ">open(filePath, 'r') as file:<|endoftext|>\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "for outputs in outputs_list:\n",
    "    parts = tokenizer.decode(outputs[0]).split('<fim')\n",
    "    for i in range(len(parts)):\n",
    "        if (i == len(parts)-1):\n",
    "            print(\"Predicted:\")\n",
    "            predicted.append(parts[i][8 :]) \n",
    "        print(parts[i][7 :])\n",
    "    print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed9687d-61d8-4984-90cd-09b903510049",
   "metadata": {},
   "source": [
    "Ignoring the excess code after the correct answer has been generated (like the second output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a04a84d-41f6-4a36-b8c9-70d1c564b328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated code provides logically at least logically correct beginning in the 45.83333333333333% amount of cases\n"
     ]
    }
   ],
   "source": [
    "true_labels = [0, 1, 3, 8, 9, 12, 13, 19, 20, 22, 23]\n",
    "false_labels = [2, 4, 5, 6, 7, 10, 11, 14, 15, 16, 17, 18, 21]\n",
    "\n",
    "true_percentage = len(true_labels)/(len(true_labels)+len(false_labels)) * 100\n",
    "print('Generated code provides logically at least logically correct beginning in the '+str(true_percentage)+'% amount of cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77de55-9f00-4dfe-8975-703428327171",
   "metadata": {},
   "source": [
    "Not accepting anything but the logically correct code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91ab91bc-efd2-4050-a321-9844bf915d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated code is absolutely logically correct in the 25.0% amount of cases\n"
     ]
    }
   ],
   "source": [
    "true_labels = [0, 12, 13, 19, 20, 23]\n",
    "false_labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 21, 22]\n",
    "\n",
    "true_percentage = len(true_labels)/(len(true_labels)+len(false_labels)) * 100\n",
    "print('Generated code is absolutely logically correct in the '+str(true_percentage)+'% amount of cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8be2a39-0ee0-44f0-980a-92994b141ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87f6b580-6f29-4c0d-9903-1b1eb8d9332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predicted)):\n",
    "    if predicted[i].endswith('<|endoftext|>'):\n",
    "        predicted[i] = predicted[i][: -len('<|endoftext|>')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1abadb06-f181-46c8-a899-1af75bd449f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    diff = np.array(vector1) - np.array(vector2)\n",
      "    distance = sum([abs(x) for x in diff])\n",
      "\n",
      "    diff = np.array(vector1) - np.array(vector2)\n",
      "    distance = sum([abs(x) for x in diff])\n",
      "\n",
      "    diff = (np.array(vector1) - np.array(vector2))**2\n",
      "    distance = np.sqrt(np.sum(diff))\n",
      "\n",
      "    diff = (np.array(vector1) - np.array(vector2))**2\n",
      "    distance = np.sqrt(np.sum(diff))\n",
      "\n",
      "    with open(filePath, 'r') as file:\n",
      "        fasta_sequences_sars1 = SeqIO.parse(file,'fasta')\n",
      "\n",
      "    with open(filePath, 'r') as file:\n",
      "        fasta_sequences_sars1 = SeqIO.parse(file,'fasta')\n",
      "\n",
      "    #encode RNA codon (triplet) as one number in 5-adic system\n",
      "    encoding = ''\n",
      "    \n",
      "    for nucleotide in rna_codon:\n",
      "        if nucleotide == 'C':\n",
      "            encoding += '1'\n",
      "        elif nucleotide == 'A':\n",
      "            encoding += '2'\n",
      "        elif nucleotide == 'T':\n",
      "            encoding += '3'\n",
      "        else: # nucleotide == G\n",
      "            encoding += '4'\n",
      "            \n",
      "\n",
      "    encoded_codon1 = five_adic_codon_encoding(codon1)\n",
      "    encoded_codon2 = five_adic_codon_encoding(codon2)\n",
      "    \n",
      "    distance = 0\n",
      "    if int(encoded_codon1/100) != int(encoded_codon2/100):\n",
      "        distance = 1\n",
      "\n",
      "    elif int(encoded_codon1/10) != int(encoded_codon2/10):\n",
      "        distance = 1/5\n",
      "        \n",
      "    elif encoded_codon1 % 10 != encoded_codon2 % 10:\n",
      "        if abs(encoded_codon1 % 10 - encoded_codon2 % 10) == 2:\n",
      "            distance = 1/2*1/25\n",
      "        else:\n",
      "            distance = 1*1/25\n",
      "\n",
      "    print('one')\n",
      "    print('two')\n",
      "\n",
      "    print('one')\n",
      "    print('two')\n",
      "\n",
      "    print('one')\n",
      "    print('two')\n",
      "\n",
      "    print('one')\n",
      "    print('two')\n",
      "\n",
      "    print(\"Hello world!\")\n",
      "\n",
      "    print(\"Hello world!\")\n",
      "\n",
      "elif nucleotide == 'A':\n",
      "            encoding += '2'\n",
      "        \n",
      "elif int(encoded_codon1/10) != int(encoded_codon2/10):\n",
      "        distance = 1/5\n",
      "        \n",
      "    \n",
      "elif int(encoded_codon1/10) != int(encoded_codon2/10):\n",
      "        distance = 1/5\n",
      "        \n",
      "    \n",
      "diff = np.array(vector1) - np.array(vector2)\n",
      "    \n",
      "distance = sum([abs(x) for x in diff])\n",
      "    \n",
      "diff = (np.array(vector1) - np.array(vector2))**2\n",
      "    \n",
      "distance = np.sqrt(np.sum(diff))\n",
      "    \n",
      "def print_hello_world():\n",
      "print('one')\n",
      "    \n",
      "open(filePath, 'r') as file:\n"
     ]
    }
   ],
   "source": [
    "y_true\n",
    "\n",
    "for y_true_i in y_true:\n",
    "    print(y_true_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da5c5f51-d515-45d9-8f74-66f5145c8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be41f44a-20c1-4433-877b-031f1d400aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match_metric = load(\"exact_match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceedfa47-7697-4aab-91fa-cea9a545ea8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': np.float64(0.08333333333333333)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_match_metric.compute(predictions=predicted, references=y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc9e243-fcf7-4f67-abf0-507cb78a61f1",
   "metadata": {},
   "source": [
    "exact_match is too strict. It only values models that learnt \"by heart\". My assumption is that models which have very high exact_match scores on training sets are overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b19585c2-ccc4-4c1e-8588-889543f9bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrf = load(\"chrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "232a3388-bb5a-4ad1-b8dc-ecb30b889ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 35.38802787294197, 'char_order': 6, 'word_order': 0, 'beta': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrf.compute(predictions=predicted, references=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6b41543-a9b6-4fe5-beb4-99466cd7a542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 35.618361089768904, 'char_order': 6, 'word_order': 1, 'beta': 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrf.compute(predictions=predicted, references=y_true, word_order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f68f9ce4-e837-42f9-ae4f-00d7fadd9805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 33.55617593813577, 'char_order': 6, 'word_order': 2, 'beta': 2}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrf.compute(predictions=predicted, references=y_true, word_order=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1cc7b-bb7c-41f3-922f-75a30238fb19",
   "metadata": {},
   "source": [
    "chrf, chrf+ and chrf++ seem to provide much better estimation of the quality of model's predictions. The score is higher 25%, that is the lower boundary (according to my judgement). Also, the score is not higher than 46%, which is the upper boundary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_completion",
   "language": "python",
   "name": "code_completion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
